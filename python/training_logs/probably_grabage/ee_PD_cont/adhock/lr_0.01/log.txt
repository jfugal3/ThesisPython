Logging to training_logs/ee_PD_cont/adhock/lr_0.01
---------------------------------
| explained_variance | 0.0277   |
| fps                | 52       |
| nupdates           | 1        |
| policy_entropy     | 4.26     |
| policy_loss        | -0.27    |
| total_timesteps    | 0        |
| value_loss         | 5.16     |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 3.68e+03 |
| explained_variance | -0.0594  |
| fps                | 111      |
| nupdates           | 100      |
| policy_entropy     | 4.27     |
| policy_loss        | -0.0929  |
| total_timesteps    | 8019     |
| value_loss         | 0.051    |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 6.45e+03 |
| explained_variance | 0.457    |
| fps                | 109      |
| nupdates           | 200      |
| policy_entropy     | 4.25     |
| policy_loss        | -0.232   |
| total_timesteps    | 16119    |
| value_loss         | 0.00505  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 7.73e+03 |
| explained_variance | 0.307    |
| fps                | 108      |
| nupdates           | 300      |
| policy_entropy     | 4.19     |
| policy_loss        | -0.156   |
| total_timesteps    | 24219    |
| value_loss         | 0.00673  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 8.41e+03 |
| explained_variance | -0.148   |
| fps                | 108      |
| nupdates           | 400      |
| policy_entropy     | 4.17     |
| policy_loss        | -0.158   |
| total_timesteps    | 32319    |
| value_loss         | 0.0139   |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 8.86e+03 |
| explained_variance | -0.361   |
| fps                | 108      |
| nupdates           | 500      |
| policy_entropy     | 4.14     |
| policy_loss        | 0.101    |
| total_timesteps    | 40419    |
| value_loss         | 0.0116   |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 9.21e+03 |
| explained_variance | -0.0581  |
| fps                | 108      |
| nupdates           | 600      |
| policy_entropy     | 4.11     |
| policy_loss        | 0.00366  |
| total_timesteps    | 48519    |
| value_loss         | 0.00369  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 9.48e+03 |
| explained_variance | -0.0767  |
| fps                | 108      |
| nupdates           | 700      |
| policy_entropy     | 4.07     |
| policy_loss        | -0.0348  |
| total_timesteps    | 56619    |
| value_loss         | 0.00903  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 9.7e+03  |
| explained_variance | 0.539    |
| fps                | 108      |
| nupdates           | 800      |
| policy_entropy     | 4.05     |
| policy_loss        | -0.0443  |
| total_timesteps    | 64719    |
| value_loss         | 0.0099   |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 9.91e+03 |
| explained_variance | 0.179    |
| fps                | 108      |
| nupdates           | 900      |
| policy_entropy     | 4.01     |
| policy_loss        | -0.313   |
| total_timesteps    | 72819    |
| value_loss         | 0.00809  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.01e+04 |
| explained_variance | 0.516    |
| fps                | 108      |
| nupdates           | 1000     |
| policy_entropy     | 3.99     |
| policy_loss        | -0.0646  |
| total_timesteps    | 80919    |
| value_loss         | 0.00455  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.03e+04 |
| explained_variance | 0.522    |
| fps                | 108      |
| nupdates           | 1100     |
| policy_entropy     | 3.96     |
| policy_loss        | -0.221   |
| total_timesteps    | 89019    |
| value_loss         | 0.00639  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.04e+04 |
| explained_variance | 0.57     |
| fps                | 108      |
| nupdates           | 1200     |
| policy_entropy     | 3.93     |
| policy_loss        | -0.0518  |
| total_timesteps    | 97119    |
| value_loss         | 0.00215  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.06e+04 |
| explained_variance | 0.523    |
| fps                | 108      |
| nupdates           | 1300     |
| policy_entropy     | 3.9      |
| policy_loss        | -0.16    |
| total_timesteps    | 105219   |
| value_loss         | 0.00306  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.12e+04 |
| explained_variance | 0.629    |
| fps                | 108      |
| nupdates           | 1400     |
| policy_entropy     | 3.87     |
| policy_loss        | -0.0537  |
| total_timesteps    | 113319   |
| value_loss         | 0.00293  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.14e+04 |
| explained_variance | -0.0637  |
| fps                | 108      |
| nupdates           | 1500     |
| policy_entropy     | 3.83     |
| policy_loss        | -0.27    |
| total_timesteps    | 121419   |
| value_loss         | 0.00363  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.16e+04 |
| explained_variance | 0.579    |
| fps                | 108      |
| nupdates           | 1600     |
| policy_entropy     | 3.81     |
| policy_loss        | -0.104   |
| total_timesteps    | 129519   |
| value_loss         | 0.00373  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.18e+04 |
| explained_variance | 0.601    |
| fps                | 108      |
| nupdates           | 1700     |
| policy_entropy     | 3.78     |
| policy_loss        | -0.211   |
| total_timesteps    | 137619   |
| value_loss         | 0.00155  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.2e+04  |
| explained_variance | 0.476    |
| fps                | 108      |
| nupdates           | 1800     |
| policy_entropy     | 3.75     |
| policy_loss        | 0.019    |
| total_timesteps    | 145719   |
| value_loss         | 0.00367  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.21e+04 |
| explained_variance | -0.652   |
| fps                | 107      |
| nupdates           | 1900     |
| policy_entropy     | 3.71     |
| policy_loss        | -0.199   |
| total_timesteps    | 153819   |
| value_loss         | 0.00339  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.22e+04 |
| explained_variance | 0.213    |
| fps                | 107      |
| nupdates           | 2000     |
| policy_entropy     | 3.66     |
| policy_loss        | -0.0337  |
| total_timesteps    | 161919   |
| value_loss         | 0.00351  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.24e+04 |
| explained_variance | 0.357    |
| fps                | 107      |
| nupdates           | 2100     |
| policy_entropy     | 3.62     |
| policy_loss        | -0.127   |
| total_timesteps    | 170019   |
| value_loss         | 0.0016   |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.25e+04 |
| explained_variance | -0.31    |
| fps                | 107      |
| nupdates           | 2200     |
| policy_entropy     | 3.6      |
| policy_loss        | -0.378   |
| total_timesteps    | 178119   |
| value_loss         | 0.00267  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.25e+04 |
| explained_variance | -0.176   |
| fps                | 107      |
| nupdates           | 2300     |
| policy_entropy     | 3.55     |
| policy_loss        | 0.15     |
| total_timesteps    | 186219   |
| value_loss         | 0.00259  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.26e+04 |
| explained_variance | -0.314   |
| fps                | 108      |
| nupdates           | 2400     |
| policy_entropy     | 3.53     |
| policy_loss        | -0.0948  |
| total_timesteps    | 194319   |
| value_loss         | 0.00193  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.27e+04 |
| explained_variance | -0.095   |
| fps                | 108      |
| nupdates           | 2500     |
| policy_entropy     | 3.52     |
| policy_loss        | -0.041   |
| total_timesteps    | 202419   |
| value_loss         | 0.00204  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.27e+04 |
| explained_variance | 0.426    |
| fps                | 108      |
| nupdates           | 2600     |
| policy_entropy     | 3.5      |
| policy_loss        | -0.268   |
| total_timesteps    | 210519   |
| value_loss         | 0.00258  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.28e+04 |
| explained_variance | 0.0476   |
| fps                | 108      |
| nupdates           | 2700     |
| policy_entropy     | 3.47     |
| policy_loss        | -0.211   |
| total_timesteps    | 218619   |
| value_loss         | 0.00247  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.28e+04 |
| explained_variance | 0.507    |
| fps                | 108      |
| nupdates           | 2800     |
| policy_entropy     | 3.47     |
| policy_loss        | -0.145   |
| total_timesteps    | 226719   |
| value_loss         | 0.00204  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.29e+04 |
| explained_variance | 0.551    |
| fps                | 108      |
| nupdates           | 2900     |
| policy_entropy     | 3.47     |
| policy_loss        | 0.174    |
| total_timesteps    | 234819   |
| value_loss         | 0.00291  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.29e+04 |
| explained_variance | 0.488    |
| fps                | 108      |
| nupdates           | 3000     |
| policy_entropy     | 3.45     |
| policy_loss        | -0.207   |
| total_timesteps    | 242919   |
| value_loss         | 0.00174  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.29e+04 |
| explained_variance | 0.615    |
| fps                | 108      |
| nupdates           | 3100     |
| policy_entropy     | 3.45     |
| policy_loss        | -0.0597  |
| total_timesteps    | 251019   |
| value_loss         | 0.00214  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.3e+04  |
| explained_variance | 0.573    |
| fps                | 108      |
| nupdates           | 3200     |
| policy_entropy     | 3.44     |
| policy_loss        | 0.0649   |
| total_timesteps    | 259119   |
| value_loss         | 0.00217  |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.3e+04  |
| explained_variance | 0.605    |
| fps                | 108      |
| nupdates           | 3300     |
| policy_entropy     | 3.43     |
| policy_loss        | -0.158   |
| total_timesteps    | 267219   |
| value_loss         | 0.0016   |
---------------------------------
---------------------------------
| ep_len_mean        | 1e+03    |
| ep_reward_mean     | 1.3e+04  |
| explained_variance | 0.624    |
| fps                | 108      |
| nupdates           | 3400     |
| policy_entropy     | 3.4      |
| policy_loss        | -0.119   |
| total_timesteps    | 275319   |
| value_loss         | 0.00182  |
---------------------------------
