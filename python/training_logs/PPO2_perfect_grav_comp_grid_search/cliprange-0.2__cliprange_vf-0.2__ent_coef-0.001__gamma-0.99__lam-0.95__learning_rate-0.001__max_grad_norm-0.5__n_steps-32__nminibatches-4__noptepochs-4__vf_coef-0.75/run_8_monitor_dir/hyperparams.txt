{'lam': 0.95, 'n_steps': 32, 'cliprange': 0.2, 'cliprange_vf': 0.2, 'ent_coef': 0.001, 'learning_rate': 0.001, 'vf_coef': 0.75, 'noptepochs': 4, 'max_grad_norm': 0.5, 'nminibatches': 4, 'gamma': 0.99}
n_envs = 4
RLAgent = <class 'stable_baselines.ppo2.ppo2.PPO2'>
Env = 1goal_perfect_comp
