{'gamma': 0.99, 'n_steps': 32, 'cliprange': 0.2, 'nminibatches': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.25, 'learning_rate': 0.001, 'noptepochs': 4, 'ent_coef': 0.0, 'lam': 0.95, 'cliprange_vf': 0.2}
n_envs = 4

env = 1goal_perfect_comp
RLAgent = <class 'stable_baselines.ppo2.ppo2.PPO2'>
