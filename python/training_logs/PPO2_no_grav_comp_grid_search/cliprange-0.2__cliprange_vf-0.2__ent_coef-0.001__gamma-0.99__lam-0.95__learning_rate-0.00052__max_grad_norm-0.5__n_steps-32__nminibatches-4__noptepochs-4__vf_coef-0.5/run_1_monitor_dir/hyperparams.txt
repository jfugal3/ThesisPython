{'lam': 0.95, 'n_steps': 32, 'gamma': 0.99, 'noptepochs': 4, 'learning_rate': 0.00052, 'nminibatches': 4, 'vf_coef': 0.5, 'cliprange_vf': 0.2, 'ent_coef': 0.001, 'max_grad_norm': 0.5, 'cliprange': 0.2}
n_envs = 4
RLAgent = <class 'stable_baselines.ppo2.ppo2.PPO2'>
Env = 1goal_no_comp
